{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader"
   ],
   "id": "720e78d6ef75df2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from ResampleGAN.core.ModelManager import ModelManager\n",
    "from ResampleGAN.core.TrainingUtils import TrainingUtils, quick_setup\n",
    "from ResampleGAN.utils.DatasetGenerator import DatasetGenerator, get_aligned_input_output\n",
    "from ResampleGAN.core.ErrorUtils import compute_metrics\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple"
   ],
   "id": "5a90d8f1ee33f52e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class BaselineConfig:\n",
    "    device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # model config\n",
    "    dim_attention: int = 128\n",
    "    num_heads: int = 4\n",
    "    dim_feedforward: int = 128\n",
    "    dropout: float = 0.1\n",
    "    num_layers: int = 6\n",
    "    with_bias: bool = False\n",
    "    attention_type: List = None\n",
    "\n",
    "    # training config\n",
    "    n_epochs: int = 120\n",
    "    batch_size: int = 64\n",
    "    dim_input: int = 1\n",
    "    hidden_dim: int = 16\n",
    "    grad_clip_threshold: float = 10.0\n",
    "\n",
    "    # optimizer config\n",
    "    lr: float = 1e-3\n",
    "    weight_decay: float = 1e-3\n",
    "\n",
    "    # 颜色配置\n",
    "    blue: str = '#0C5DA5'\n",
    "    green: str = '#00B945'\n",
    "    orange: str = '#FF9500'\n",
    "    red: str = '#FF2C00'\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.attention_type is None:\n",
    "            self.attention_type = [[\"original\"]*3, [\"conv\"]*0, [\"freq\"]*0]"
   ],
   "id": "6a13f5f971b78134",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "config = BaselineConfig()\n",
    "TrainingUtils.set_seed(42)\n",
    "logger, device = quick_setup(log_file=\"baseline_training.log\")\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ],
   "id": "f16e9f2553af7660",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_baseline_model(model_type: str, waveform: str, train_loader, valid_loader, config, logger):\n",
    "    \"\"\"Simplified baseline model training function\"\"\"\n",
    "\n",
    "    # Create model manager and model\n",
    "    manager = ModelManager(logger, config)\n",
    "    model = manager.create_model(model_type)\n",
    "\n",
    "    # Create optimizer and loss function\n",
    "    optimizer = manager.create_optimizer(model)\n",
    "    scheduler = manager.create_scheduler(optimizer)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Print model information\n",
    "    manager.print_model_summary(model, f\"{model_type}\")\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    train_losses, valid_losses = [], []\n",
    "\n",
    "    logger.info(f\"Starting training {model_type} - {waveform}\")\n",
    "\n",
    "    for epoch in range(config.n_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Parse batch data\n",
    "            x_input, x_initial, x_mask, x_output, mask, condition = batch\n",
    "            x_input = x_input.to(config.device)\n",
    "            x_initial = x_initial.to(config.device)\n",
    "            x_output = x_output.to(config.device) if x_output is not None else None\n",
    "            s_in, s_out = condition[0], condition[1]\n",
    "\n",
    "            # Select inference method based on model type\n",
    "            if model_type == \"TCN\":\n",
    "                pred = model(x_initial)\n",
    "            elif model_type in [\"LSTM\"]:\n",
    "                pred = model(x_initial)\n",
    "            elif model_type == \"Transformer\":\n",
    "                pred = model(x_input, x_initial, s_in, s_out, with_clamp=False)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(pred, x_output)\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip_threshold)\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        total_valid_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in valid_loader:\n",
    "                x_input, x_initial, x_mask, x_output, mask, condition = batch\n",
    "                x_input = x_input.to(config.device)\n",
    "                x_initial = x_initial.to(config.device)\n",
    "                x_output = x_output.to(config.device) if x_output is not None else None\n",
    "                s_in, s_out = condition[0], condition[1]\n",
    "\n",
    "                if model_type == \"TCN\":\n",
    "                    pred = model(x_initial)\n",
    "                elif model_type in [\"LSTM\"]:\n",
    "                    pred = model(x_initial)\n",
    "                elif model_type == \"Transformer\":\n",
    "                    pred = model(x_input, x_initial, s_in, s_out, with_clamp=False)\n",
    "\n",
    "                loss = criterion(pred, x_output)\n",
    "                total_valid_loss += loss.item()\n",
    "\n",
    "        # Calculate average loss\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_valid_loss = total_valid_loss / len(valid_loader)\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        valid_losses.append(avg_valid_loss)\n",
    "\n",
    "        # Update learning rate\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Save best model\n",
    "        if avg_valid_loss < best_loss:\n",
    "            best_loss = avg_valid_loss\n",
    "            save_path = f\"../results/001_baseline_selection/model/best_{model_type}_model_{waveform}.pth\"\n",
    "            os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "\n",
    "        # Print every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            logger.info(f\"Epoch {epoch+1}/{config.n_epochs} | Train: {avg_train_loss:.6f} | Valid: {avg_valid_loss:.6f}\")\n",
    "\n",
    "    logger.info(f\"{model_type} - {waveform} training completed\")\n",
    "    return model, train_losses, valid_losses"
   ],
   "id": "c4f91b7bf186b582",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "os.makedirs(\"../results/001_baseline_selection/model\", exist_ok=True)\n",
    "os.makedirs(\"../results/001_baseline_selection/picture\", exist_ok=True)\n",
    "\n",
    "waveforms = [\"line\", \"square\", \"sine\", \"triangle\"]\n",
    "# waveforms = [\"line\"]\n",
    "model_types = [\"Transformer\", \"TCN\", \"LSTM\"]"
   ],
   "id": "97a3b899e17c885f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for waveform in waveforms:\n",
    "    logger.info(f\"Processing waveform: {waveform}\")\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv(f\"../dataset/special_wave_{waveform}.csv\")\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "    df.set_index(\"time\", inplace=True)\n",
    "    df = df[[\"value\"]]\n",
    "\n",
    "    # Process data\n",
    "    df_input, df_output = get_aligned_input_output(df, s_in=\"15min\", s_out=\"5min\")\n",
    "    dataset = DatasetGenerator(\n",
    "        df_input=df_input,\n",
    "        df_output=df_output,\n",
    "        input_length=97,\n",
    "        output_length=289,\n",
    "        s_in=\"15min\",\n",
    "        s_out=\"5min\",\n",
    "        use_window=True\n",
    "    )\n",
    "\n",
    "    # Split preprocessed\n",
    "    train_dataset, test_dataset, valid_dataset = DatasetGenerator.split_dataset(dataset)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "    # Train each model\n",
    "    for model_type in model_types:\n",
    "        try:\n",
    "            model, train_losses, valid_losses = train_baseline_model(model_type, waveform, train_loader, valid_loader, config, logger)\n",
    "            logger.info(f\"{model_type} training completed for {waveform}\")\n",
    "        except Exception as e:\n",
    "            logger.info(f\"{model_type} training failed: {e}\")\n",
    "\n",
    "        # Clean up memory\n",
    "        TrainingUtils.cleanup_memory()\n",
    "\n",
    "logger.info(\"All models trained successfully\")"
   ],
   "id": "afc59eea2d4977aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import scienceplots\n",
    "plt.style.use(['science', \"no-latex\"])\n",
    "df_rmse = pd.DataFrame(index=[\"TCN\", \"LSTM\", \"Transformer_simple\"],\n",
    "                       columns=[\"line\", \"square\", \"sine\", \"triangle\"])\n",
    "df_pcc = pd.DataFrame(index=[\"TCN\", \"LSTM\", \"Transformer_simple\"],\n",
    "                      columns=[\"line\", \"square\", \"sine\", \"triangle\"])"
   ],
   "id": "ec160196af17f146",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(14, 3), dpi=300)\n",
    "\n",
    "for i, waveform in enumerate([\"line\", \"square\", \"sine\", \"triangle\"]):\n",
    "    print(f\"Evaluating waveform: {waveform}\")\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv(f\"../dataset/special_wave_{waveform}.csv\")\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "    df.set_index(\"time\", inplace=True)\n",
    "    df = df[[\"value\"]]\n",
    "\n",
    "    df_input, df_output = get_aligned_input_output(df, s_in=\"15min\", s_out=\"5min\")\n",
    "    dataset = DatasetGenerator(\n",
    "        df_input=df_input,\n",
    "        df_output=df_output,\n",
    "        input_length=97,\n",
    "        output_length=289,\n",
    "        s_in=\"15min\",\n",
    "        s_out=\"5min\",\n",
    "        use_window=True,\n",
    "    )\n",
    "\n",
    "    _, _, valid_dataset = DatasetGenerator.split_dataset(dataset)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=len(valid_dataset), shuffle=False)\n",
    "\n",
    "    # Get validation data\n",
    "    for batch in valid_loader:\n",
    "        x_input, x_initial, x_mask, x_output, mask, condition = batch\n",
    "        x_input = x_input.to(config.device)\n",
    "        x_initial = x_initial.to(config.device)\n",
    "        x_output = x_output.to(config.device)\n",
    "        s_in, s_out = condition[0], condition[1]\n",
    "        break\n",
    "\n",
    "    # Evaluate each model\n",
    "    manager = ModelManager(logger, config)\n",
    "\n",
    "    for model_type in [\"TCN\", \"Transformer\", \"LSTM\"]:\n",
    "        try:\n",
    "            # Load model\n",
    "            model = manager.create_model(model_type)\n",
    "            model_path = f\"../results/001_baseline_selection/model/best_{model_type}_model_{waveform}.pth\"\n",
    "\n",
    "            if os.path.exists(model_path):\n",
    "                model = manager.load_model(model, model_path)\n",
    "                model.eval()\n",
    "\n",
    "                # Inference\n",
    "                with torch.no_grad():\n",
    "                    if model_type == \"TCN\":\n",
    "                        output = model(x_initial)\n",
    "                    elif model_type in [\"LSTM\",]:\n",
    "                        output = model(x_initial)\n",
    "                    elif model_type == \"Transformer\":\n",
    "                        output = model(x_input, x_initial, s_in, s_out, with_clamp=False)\n",
    "\n",
    "                # Calculate metrics\n",
    "                pred = output.cpu().numpy()\n",
    "                real = x_output.cpu().numpy()\n",
    "\n",
    "                rmse_model, pcc_model, mag_model, phase_model = compute_metrics(real, pred)\n",
    "                df_rmse.loc[model_type, waveform] = rmse_model\n",
    "                df_pcc.loc[model_type, waveform] = pcc_model\n",
    "\n",
    "                # Plot\n",
    "                color_map = {\"TCN\": config.green, \"LSTM\": config.orange, \"Transformer\": config.red}\n",
    "                axes[i].plot(pred[0], label=model_type, color=color_map[model_type], linewidth=1.5)\n",
    "\n",
    "                print(f\"{model_type}: RMSE={rmse_model:.4f}, PCC={pcc_model:.4f}\")\n",
    "            else:\n",
    "                print(f\"{model_type} model file does not exist\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{model_type} evaluation failed: {e}\")\n",
    "\n",
    "    # Plot real values\n",
    "    axes[i].plot(x_output.cpu().numpy()[0], label=\"Real\", color=config.blue, linewidth=2)\n",
    "    axes[i].set_title(waveform.capitalize(), fontsize=12)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "    if i > 0:\n",
    "        axes[i].set_ylabel('')\n",
    "        axes[i].set_yticklabels([])\n",
    "\n",
    "# Add legend\n",
    "legend_elements = [\n",
    "    plt.Line2D([0], [0], color=config.blue, linewidth=2, label='Real'),\n",
    "    plt.Line2D([0], [0], color=config.red, linewidth=1.5, label='Transformer'),\n",
    "    plt.Line2D([0], [0], color=config.orange, linewidth=1.5, label='LSTM'),\n",
    "    plt.Line2D([0], [0], color=config.green, linewidth=1.5, label='TCN'),\n",
    "]\n",
    "\n",
    "axes[0].legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(2, -0.05),\n",
    "               ncol=4, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../results/001_baseline_selection/picture/A_1_baseline_selection.pdf\",\n",
    "            dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save results\n",
    "df_rmse.to_csv(\"../results/001_baseline_selection/rmse_results.csv\")\n",
    "df_pcc.to_csv(\"../results/001_baseline_selection/pcc_results.csv\")"
   ],
   "id": "4f143a138b053786",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d49e602a4e66e0b2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
