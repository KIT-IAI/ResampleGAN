{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-30T13:16:21.077641Z",
     "start_time": "2025-06-30T13:16:11.982004Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from ResampleGAN.utils.DatasetGenerator import DatasetGenerator\n",
    "from ResampleGAN.core.ModelManager import ModelManager\n",
    "from ResampleGAN.TransGAN.Discriminator import Discriminator\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:16:21.896476Z",
     "start_time": "2025-06-30T13:16:21.235663Z"
    }
   },
   "cell_type": "code",
   "source": "from ResampleGAN.core.ErrorUtils import compute_metrics",
   "id": "b52eca85c20fa43f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:16:21.911898Z",
     "start_time": "2025-06-30T13:16:21.904643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_waveform(waveform, mc):\n",
    "    if waveform == \"electric\":\n",
    "        df = pd.read_csv(f\"../dataset/preprocessed/electric.csv\")\n",
    "        df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "        df.set_index(\"time\", inplace=True)\n",
    "        df = df[[\"P_1\"]]\n",
    "        df_input = df.resample(\"15min\").first().ffill()\n",
    "        df_output = df.resample(\"5min\").first().ffill()\n",
    "\n",
    "        dataset = DatasetGenerator(\n",
    "            df_input=df_input,\n",
    "            df_output=df_output,\n",
    "            input_length=97,\n",
    "            output_length=289,\n",
    "            s_in=\"15min\",\n",
    "            s_out=\"5min\",\n",
    "            use_window=True,\n",
    "            extra_interpolate=True,\n",
    "        )\n",
    "        print(len(dataset))\n",
    "        train_dataset, test_dataset,_ = DatasetGenerator.split_dataset(dataset, train_ratio=0.7, test_ratio=0.3, valid_ratio=0.0)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "    elif waveform == \"pv\" :\n",
    "        df = pd.read_csv(f\"../dataset/preprocessed/pv.csv\")\n",
    "        df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "        df.set_index(\"datetime\", inplace=True)\n",
    "        df = df[[\"Gg_pyr\"]]\n",
    "        df_input = df.resample(\"15min\").first().ffill()\n",
    "        df_output = df.resample(\"5min\").first().ffill()\n",
    "\n",
    "        dataset = DatasetGenerator(\n",
    "            df_input=df_input,\n",
    "            df_output=df_output,\n",
    "            input_length=97,\n",
    "            output_length=289,\n",
    "            s_in=\"15min\",\n",
    "            s_out=\"5min\",\n",
    "            use_window=True,\n",
    "            extra_interpolate=True,\n",
    "        )\n",
    "        print(len(dataset))\n",
    "        train_dataset, test_dataset,_ = DatasetGenerator.split_dataset(dataset, train_ratio=0.7, test_ratio=0.3, valid_ratio=0.0)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "    elif waveform == \"wind\":\n",
    "        df = pd.read_csv(f\"../dataset/preprocessed/wind_1.csv\")\n",
    "        df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "        df.set_index(\"time\", inplace=True)\n",
    "        df = df[[\"observed\"]]\n",
    "        df_input = df.resample(\"15min\").first().ffill()\n",
    "        df_output = df.resample(\"5min\").first().ffill()\n",
    "\n",
    "        dataset_1 = DatasetGenerator(\n",
    "            df_input=df_input,\n",
    "            df_output=df_output,\n",
    "            input_length=97,\n",
    "            output_length=289,\n",
    "            s_in=\"15min\",\n",
    "            s_out=\"5min\",\n",
    "            use_window=True,\n",
    "            extra_interpolate=True,\n",
    "        )\n",
    "\n",
    "        df = pd.read_csv(f\"../dataset/preprocessed/wind_2.csv\")\n",
    "        df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "        df.set_index(\"time\", inplace=True)\n",
    "        df = df[[\"observed\"]]\n",
    "        df_input = df.resample(\"15min\").first().ffill()\n",
    "        df_output = df.resample(\"5min\").first().ffill()\n",
    "\n",
    "        dataset_2 = DatasetGenerator(\n",
    "            df_input=df_input,\n",
    "            df_output=df_output,\n",
    "            input_length=97,\n",
    "            output_length=289,\n",
    "            s_in=\"15min\",\n",
    "            s_out=\"5min\",\n",
    "            use_window=True,\n",
    "            extra_interpolate=True,\n",
    "        )\n",
    "        dataset = ConcatDataset([dataset_1, dataset_2])\n",
    "        print(len(dataset))\n",
    "        train_dataset, test_dataset,_ = DatasetGenerator.split_dataset(dataset, train_ratio=0.7, test_ratio=0.3, valid_ratio=0.0)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "    elif waveform == \"mpv\":\n",
    "        df = pd.read_csv(f\"../dataset/p_watt_15min.csv\")\n",
    "        df_input = pd.read_csv(f\"../dataset/p_watt_15min.csv\")\n",
    "        df_output = pd.read_csv(f\"../dataset/p_watt_5min.csv\")\n",
    "        df_input[\"time\"] = pd.to_datetime(df_input[\"time\"])\n",
    "        df_input.set_index(\"time\", inplace=True)\n",
    "        df_input = df_input[[\"1a\"]]\n",
    "        df_output[\"time\"] = pd.to_datetime(df_output[\"time\"])\n",
    "        df_output.set_index(\"time\", inplace=True)\n",
    "        df_output = df_output[[\"1a\"]]\n",
    "        dataset = DatasetGenerator(\n",
    "            df_input=df_input,\n",
    "            df_output=df_output,\n",
    "            input_length=97,\n",
    "            output_length=289,\n",
    "            s_in=\"15min\",\n",
    "            s_out=\"5min\",\n",
    "            use_window=True,\n",
    "            extra_interpolate=True,\n",
    "        )\n",
    "        print(len(dataset))\n",
    "        train_dataset, test_dataset,_ = DatasetGenerator.split_dataset(dataset, train_ratio=0.7, test_ratio=0.3, valid_ratio=0.0)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=len(train_dataset), shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid waveform\")\n",
    "\n",
    "    return train_loader, test_loader"
   ],
   "id": "b8f503eedf0a2a6b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:16:21.924067Z",
     "start_time": "2025-06-30T13:16:21.920258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ModelConfig:\n",
    "    def __init__(self):\n",
    "        # Device and environment configuration\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Generator configuration\n",
    "        self.dim_attention = 128\n",
    "        self.num_heads = 4\n",
    "        self.dim_feedforward = 128\n",
    "        self.dropout = 0.1\n",
    "        self.num_layers = 6\n",
    "        self.use_noise = False\n",
    "        self.restore = False\n",
    "        self.use_mask = False\n",
    "        self.with_bias = False\n",
    "        self.init_weights = False\n",
    "\n",
    "        # Training configuration\n",
    "        self.n_epochs = 360\n",
    "        self.batch_size = 64\n",
    "        self.dim_input = 1\n",
    "        self.hidden_dim = 16\n",
    "        self.grad_clip_threshold = 10\n",
    "        self.best_loss = float('inf')\n",
    "        self.no_improve_count = 0\n",
    "        self.patience = 10\n",
    "        self.use_early_stopping = False\n",
    "\n",
    "        # Optimizer configuration\n",
    "        self.optimizer_type = 'AdamW'\n",
    "        self.scheduler_type = 'WarmupCosine'\n",
    "        self.lr = 1e-3\n",
    "        self.weight_decay = 1e-3\n",
    "\n",
    "        # Scheduler configuration\n",
    "        self.mode = 'min' # ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "        self.factor = 0.5\n",
    "        self.patience = 5\n",
    "        self.total_steps = self.n_epochs * 10\n",
    "        self.warmup_steps = int(self.total_steps * 0.1)\n",
    "\n",
    "        # weights\n",
    "        self.weights = {\n",
    "            'cs_mse': 1,\n",
    "            'cs_smoothness': 1,\n",
    "            'cs_gradient': 1,\n",
    "        }"
   ],
   "id": "25768030bb219f92",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:16:21.964083Z",
     "start_time": "2025-06-30T13:16:21.932841Z"
    }
   },
   "cell_type": "code",
   "source": "mc = ModelConfig()",
   "id": "6d8a6de89c8b1e5b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:16:21.978520Z",
     "start_time": "2025-06-30T13:16:21.975938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attention_types = {\"self\":[3,0,0], \"conv\":[0,3,0], \"self+conv\":[3,3,0], \"self_conv\":[3,3,0]}\n",
    "waveforms = [\"electric\", \"pv\", \"wind\", \"mpv\"]\n",
    "# attention_types = {\"self\":[3,0,0]}\n",
    "# waveforms = [\"electric\"]"
   ],
   "id": "5a36e30664029cad",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:16:21.994084Z",
     "start_time": "2025-06-30T13:16:21.990474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "def get_immediate_subdirectories(path):\n",
    "    subdirectories = []\n",
    "    for item in os.listdir(path):\n",
    "        item_path = os.path.join(path, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            subdirectories.append(item)\n",
    "    return subdirectories\n",
    "\n",
    "# folder_path = '../results/007_all/backup'\n",
    "folder_path = '../results/002_all/reform'\n",
    "subdirs = get_immediate_subdirectories(folder_path)"
   ],
   "id": "9350036406123935",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:16:22.008979Z",
     "start_time": "2025-06-30T13:16:22.004836Z"
    }
   },
   "cell_type": "code",
   "source": "subdirs",
   "id": "59df995af665c7c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Seed_101']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:16:22.060444Z",
     "start_time": "2025-06-30T13:16:22.057384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result_order = ['Seed_49']\n",
    "result_order = subdirs\n",
    "# backup_path = \"../results/007_all/backup\"\n",
    "backup_path = \"../results/002_all/reform\""
   ],
   "id": "57d29342440fe794",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:16:22.083277Z",
     "start_time": "2025-06-30T13:16:22.081283Z"
    }
   },
   "cell_type": "code",
   "source": "df_features = []",
   "id": "52b2a195ae62f8b5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:17:04.007835Z",
     "start_time": "2025-06-30T13:16:45.221926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for result_version in result_order:\n",
    "    path = f\"{backup_path}/{result_version}\"\n",
    "    #####################################################################\n",
    "    index_level1 = [\"RMSE\", \"PCC\", \"MAG\", \"PH\"]\n",
    "    index_level2 = [\"phase 1\", \"phase 2\", \"phase 3\", \"static\", \"only\"]\n",
    "    index_level3 = list(attention_types.keys()) + [\"linear\", \"slinear\", \"cubic\", \"quad\", \"gp\"]\n",
    "    column_level1 = waveforms\n",
    "    column_level2 = [\"train\", \"test\"]\n",
    "    multi_index = pd.MultiIndex.from_product([index_level1, index_level2, index_level3])\n",
    "    multi_column = pd.MultiIndex.from_product([column_level1, column_level2])\n",
    "    df_result = pd.DataFrame(index=multi_index, columns=multi_column)\n",
    "    df_result = df_result.sort_index()\n",
    "\n",
    "    index_level1 = [\"ACC\", \"PC\", \"RC\", \"F1\"]\n",
    "    index_level2 = [\"phase 1\", \"phase 2\", \"phase 3\", \"static\", \"only\"]\n",
    "    index_level3 = list(attention_types.keys()) + [\"linear\", \"slinear\", \"cubic\", \"quad\", \"gp\"]\n",
    "    column_level1 = waveforms\n",
    "    column_level2 = [\"train\", \"test\"]\n",
    "    multi_index = pd.MultiIndex.from_product([index_level1, index_level2, index_level3])\n",
    "    multi_column = pd.MultiIndex.from_product([column_level1, column_level2])\n",
    "    df_pred = pd.DataFrame(index=multi_index, columns=multi_column)\n",
    "    df_pred = df_pred.sort_index()\n",
    "    ########################################################################################\n",
    "    model_type = \"Transformer\"\n",
    "    for i, waveform in enumerate(waveforms):\n",
    "        train_loader, test_loader = process_waveform(waveform, mc)\n",
    "        ###################################################################################\n",
    "        with (torch.no_grad()):\n",
    "            for split, data_loader in {\"train\":train_loader, \"test\":test_loader}.items():\n",
    "                print(result_version, waveform, split)\n",
    "                for batch in data_loader:\n",
    "                    x_input, x_initial, x_mask, x_output, mask, condition, interpolate = batch\n",
    "                    x_input, x_initial, x_mask, x_output, mask, condition  = x_input.to(mc.device), x_initial.to(mc.device), x_mask.to(mc.device), x_output.to(mc.device), mask.to(mc.device), condition\n",
    "                    batch_size = x_output.size(0)\n",
    "                    s_in, s_out = condition[0], condition[1]\n",
    "\n",
    "                    real = x_output.cpu().numpy()\n",
    "                    linear = x_initial.cpu().numpy()\n",
    "                    rmse_model, pcc_model, mag_model, phase_model = compute_metrics(real, linear)\n",
    "                    df_result.loc[(\"RMSE\", \"static\", \"linear\"), (waveform, split)] = rmse_model\n",
    "                    df_result.loc[(\"PCC\", \"static\", \"linear\"), (waveform, split)] = pcc_model\n",
    "\n",
    "                    rmse_model, pcc_model, mag_model, phase_model = compute_metrics(real, interpolate[1].cpu().numpy())\n",
    "                    df_result.loc[(\"RMSE\", \"static\", \"cubic\"), (waveform, split)] = rmse_model\n",
    "                    df_result.loc[(\"PCC\", \"static\", \"cubic\"), (waveform, split)] = pcc_model\n",
    "\n",
    "                    rmse_model, pcc_model, mag_model, phase_model = compute_metrics(real, interpolate[2].cpu().numpy())\n",
    "                    df_result.loc[(\"RMSE\", \"static\", \"quad\"), (waveform, split)] = rmse_model\n",
    "                    df_result.loc[(\"PCC\", \"static\", \"quad\"), (waveform, split)] = pcc_model\n",
    "            ###################################################################################\n",
    "                    model_type = \"Transformer\"\n",
    "                    for j, (key, attention) in enumerate(attention_types.items()):\n",
    "                        if key == \"self_conv\":\n",
    "                            mc.attention_type = [[\"original\"]*attention[0],[\"conv\"]*attention[1],[\"freq\"]*attention[2]]\n",
    "                        else:\n",
    "                            mc.attention_type = [\"original\"]*attention[0]+[\"conv\"]*attention[1]+[\"freq\"]*attention[2]\n",
    "                        # phase 1\n",
    "                        manager = ModelManager(None, mc)\n",
    "                        model = manager.create_model(model_type)\n",
    "                        generator_model_path = f\"{path}/1_generator/best_generator_{key}_{waveform}_self_{attention[0]}_conv_{attention[1]}_freq_{attention[2]}.pth\"\n",
    "                        print(generator_model_path)\n",
    "                        model.load_state_dict(torch.load(generator_model_path))\n",
    "                        model.eval()\n",
    "                        for param in model.parameters():\n",
    "                            param.requires_grad = False\n",
    "                        output = model(x_input, x_initial, s_in, s_out, mask, x_mask)\n",
    "\n",
    "                        pred = output.cpu().detach().numpy()\n",
    "                        rmse_model, pcc_model, mag_model, phase_model = compute_metrics(real, pred)\n",
    "                        df_result.loc[(\"RMSE\", \"phase 1\", key), (waveform, split)] = rmse_model\n",
    "                        df_result.loc[(\"PCC\", \"phase 1\", key), (waveform, split)] = pcc_model\n",
    "                        ###################################################################################\n",
    "                        # phase 2\n",
    "                        manager = ModelManager(None, mc)\n",
    "                        model = manager.create_model(model_type)\n",
    "                        generator_model_path = f\"{path}/2_discriminator/best_generator_{key}_{waveform}_self_{attention[0]}_conv_{attention[1]}_freq_{attention[2]}.pth\"\n",
    "                        print(generator_model_path)\n",
    "                        model.load_state_dict(torch.load(generator_model_path))\n",
    "                        model.eval()\n",
    "                        for param in model.parameters():\n",
    "                            param.requires_grad = False\n",
    "\n",
    "                        output = model(x_input, x_initial, s_in, s_out, mask, x_mask)\n",
    "                        pred = output.cpu().detach().numpy()\n",
    "                        rmse_model, pcc_model, mag_model, phase_model = compute_metrics(real, pred)\n",
    "                        df_result.loc[(\"RMSE\", \"phase 2\", key), (waveform, split)] = rmse_model\n",
    "                        df_result.loc[(\"PCC\", \"phase 2\", key), (waveform, split)] = pcc_model\n",
    "\n",
    "                        discriminator = Discriminator(num_layers=mc.num_layers, dim_input=mc.dim_input, dim_attention=mc.dim_attention,\n",
    "                                          num_heads=mc.num_heads, dim_feedforward=mc.dim_feedforward, dropout=mc.dropout, attention_type=mc.attention_type,\n",
    "                                          with_bias=mc.with_bias).to(mc.device)\n",
    "                        discriminator_model_path = f\"{path}/2_discriminator/best_discriminator_{key}_{waveform}_self_{attention[0]}_conv_{attention[1]}_freq_{attention[2]}.pth\"\n",
    "                        print(discriminator_model_path)\n",
    "                        discriminator.load_state_dict(torch.load(discriminator_model_path))\n",
    "                        discriminator.eval()\n",
    "                        for param in discriminator.parameters():\n",
    "                            param.requires_grad = False\n",
    "\n",
    "                        preds_on_fake = discriminator(output, s_out)\n",
    "                        preds_on_real = discriminator(x_input, s_in)\n",
    "                        preds_on_fake_bin = (torch.sigmoid(preds_on_fake).cpu() > 0.5).int().view(-1)\n",
    "                        preds_on_real_bin = (torch.sigmoid(preds_on_real).cpu() > 0.5).int().view(-1)\n",
    "                        all_preds = preds_on_real_bin.tolist() + preds_on_fake_bin.tolist()\n",
    "                        all_labels = [1] * len(preds_on_real_bin) + [0] * len(preds_on_fake_bin)\n",
    "                        acc = accuracy_score(all_labels, all_preds)\n",
    "                        precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "                        recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "                        f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "                        df_pred.loc[(\"ACC\", \"phase 2\", key), (waveform, split)] = acc\n",
    "                        df_pred.loc[(\"PC\", \"phase 2\", key), (waveform, split)] = precision\n",
    "                        df_pred.loc[(\"RC\", \"phase 2\", key), (waveform, split)] = recall\n",
    "                        df_pred.loc[(\"F1\", \"phase 2\", key), (waveform, split)] = f1\n",
    "                        ###################################################################################\n",
    "                        # phase 3\n",
    "                        manager = ModelManager(None, mc)\n",
    "                        model = manager.create_model(model_type)\n",
    "                        generator_model_path = f\"{path}/3_generator/best_generator_{key}_{waveform}_self_{attention[0]}_conv_{attention[1]}_freq_{attention[2]}.pth\"\n",
    "                        print(generator_model_path)\n",
    "                        model.load_state_dict(torch.load(generator_model_path))\n",
    "                        model.eval()\n",
    "                        for param in model.parameters():\n",
    "                            param.requires_grad = False\n",
    "\n",
    "                        output = model(x_input, x_initial, s_in, s_out, mask, x_mask)\n",
    "                        pred = output.cpu().detach().numpy()\n",
    "                        rmse_model, pcc_model, mag_model, phase_model= compute_metrics(real, pred)\n",
    "                        df_result.loc[(\"RMSE\", \"phase 3\", key), (waveform, split)] = rmse_model\n",
    "                        df_result.loc[(\"PCC\", \"phase 3\", key), (waveform, split)] = pcc_model\n",
    "                        ###################################################################################\n",
    "                        discriminator = Discriminator(num_layers=mc.num_layers, dim_input=mc.dim_input, dim_attention=mc.dim_attention,\n",
    "                                          num_heads=mc.num_heads, dim_feedforward=mc.dim_feedforward, dropout=mc.dropout, attention_type=mc.attention_type,\n",
    "                                          with_bias=mc.with_bias).to(mc.device)\n",
    "                        discriminator_model_path = f\"{path}/2_discriminator/best_discriminator_{key}_{waveform}_self_{attention[0]}_conv_{attention[1]}_freq_{attention[2]}.pth\"\n",
    "                        print(discriminator_model_path)\n",
    "                        discriminator.load_state_dict(torch.load(discriminator_model_path))\n",
    "                        discriminator.eval()\n",
    "                        for param in discriminator.parameters():\n",
    "                            param.requires_grad = False\n",
    "\n",
    "                        preds_on_fake = discriminator(output, s_out)\n",
    "                        preds_on_real = discriminator(x_input, s_in)\n",
    "                        preds_on_fake_bin = (torch.sigmoid(preds_on_fake).cpu() > 0.5).int().view(-1)\n",
    "                        preds_on_real_bin = (torch.sigmoid(preds_on_real).cpu() > 0.5).int().view(-1)\n",
    "                        all_preds = preds_on_real_bin.tolist() + preds_on_fake_bin.tolist()\n",
    "                        all_labels = [1] * len(preds_on_real_bin) + [0] * len(preds_on_fake_bin)\n",
    "                        acc = accuracy_score(all_labels, all_preds)\n",
    "                        precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "                        recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "                        f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "                        df_pred.loc[(\"ACC\", \"phase 3\", key), (waveform, split)] = acc\n",
    "                        df_pred.loc[(\"PC\", \"phase 3\", key), (waveform, split)] = precision\n",
    "                        df_pred.loc[(\"RC\", \"phase 3\", key), (waveform, split)] = recall\n",
    "                        df_pred.loc[(\"F1\", \"phase 3\", key), (waveform, split)] = f1\n",
    "                        ###################################################################################\n",
    "\n",
    "    df_result.dropna(inplace=True)\n",
    "    df_result.to_csv(f\"{path}/features.csv\")\n",
    "    df_features.append(df_result)\n",
    "    df_pred.dropna(inplace=True)\n",
    "    df_pred.to_csv(f\"{path}/pred.csv\")"
   ],
   "id": "e205ac9e1d68681c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n",
      "Seed_101 electric train\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self_electric_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self_electric_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_electric_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self_electric_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_electric_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_conv_electric_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_conv_electric_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_conv_electric_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_conv_electric_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_conv_electric_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self+conv_electric_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self+conv_electric_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self+conv_electric_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self+conv_electric_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self+conv_electric_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self_conv_electric_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self_conv_electric_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_conv_electric_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self_conv_electric_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_conv_electric_self_3_conv_3_freq_0.pth\n",
      "Seed_101 electric test\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self_electric_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self_electric_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_electric_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self_electric_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_electric_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_conv_electric_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_conv_electric_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_conv_electric_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_conv_electric_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_conv_electric_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self+conv_electric_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self+conv_electric_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self+conv_electric_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self+conv_electric_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self+conv_electric_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self_conv_electric_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self_conv_electric_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_conv_electric_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self_conv_electric_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_conv_electric_self_3_conv_3_freq_0.pth\n",
      "363\n",
      "Seed_101 pv train\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self_pv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self_pv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_pv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self_pv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_pv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_conv_pv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_conv_pv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_conv_pv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_conv_pv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_conv_pv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self+conv_pv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self+conv_pv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self+conv_pv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self+conv_pv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self+conv_pv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self_conv_pv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self_conv_pv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_conv_pv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self_conv_pv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_conv_pv_self_3_conv_3_freq_0.pth\n",
      "Seed_101 pv test\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self_pv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self_pv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_pv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self_pv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_pv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_conv_pv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_conv_pv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_conv_pv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_conv_pv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_conv_pv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self+conv_pv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self+conv_pv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self+conv_pv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self+conv_pv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self+conv_pv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self_conv_pv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self_conv_pv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_conv_pv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self_conv_pv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_conv_pv_self_3_conv_3_freq_0.pth\n",
      "81\n",
      "Seed_101 wind train\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self_wind_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self_wind_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_wind_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self_wind_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_wind_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_conv_wind_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_conv_wind_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_conv_wind_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_conv_wind_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_conv_wind_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self+conv_wind_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self+conv_wind_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self+conv_wind_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self+conv_wind_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self+conv_wind_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self_conv_wind_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self_conv_wind_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_conv_wind_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self_conv_wind_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_conv_wind_self_3_conv_3_freq_0.pth\n",
      "Seed_101 wind test\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self_wind_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self_wind_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_wind_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self_wind_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_wind_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_conv_wind_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_conv_wind_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_conv_wind_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_conv_wind_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_conv_wind_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self+conv_wind_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self+conv_wind_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self+conv_wind_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self+conv_wind_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self+conv_wind_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self_conv_wind_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self_conv_wind_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_conv_wind_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self_conv_wind_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_conv_wind_self_3_conv_3_freq_0.pth\n",
      "364\n",
      "Seed_101 mpv train\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self_mpv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self_mpv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_mpv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self_mpv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_mpv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_conv_mpv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_conv_mpv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_conv_mpv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_conv_mpv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_conv_mpv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self+conv_mpv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self+conv_mpv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self+conv_mpv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self+conv_mpv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self+conv_mpv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self_conv_mpv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self_conv_mpv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_conv_mpv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self_conv_mpv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_conv_mpv_self_3_conv_3_freq_0.pth\n",
      "Seed_101 mpv test\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self_mpv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self_mpv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_mpv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self_mpv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_mpv_self_3_conv_0_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_conv_mpv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_conv_mpv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_conv_mpv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_conv_mpv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_conv_mpv_self_0_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self+conv_mpv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self+conv_mpv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self+conv_mpv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self+conv_mpv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self+conv_mpv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/1_generator/best_generator_self_conv_mpv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_generator_self_conv_mpv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_conv_mpv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/3_generator/best_generator_self_conv_mpv_self_3_conv_3_freq_0.pth\n",
      "../results/002_all/reform/Seed_101/2_discriminator/best_discriminator_self_conv_mpv_self_3_conv_3_freq_0.pth\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-30T13:19:22.841952Z",
     "start_time": "2025-06-30T13:19:05.875952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for waveform in waveforms:\n",
    "    #####################################################################\n",
    "    index_level1 = [\"RMSE\", \"PCC\", \"MAG\", \"PH\"]\n",
    "    index_level2 = [\"phase 1\", \"phase 2\", \"phase 3\", \"static\", \"only\"]\n",
    "    index_level3 = list(attention_types.keys()) + [\"linear\", \"slinear\", \"cubic\", \"quad\", \"gp\"]\n",
    "    column_level1 = result_order\n",
    "    column_level2 = [\"train\", \"test\"]\n",
    "    multi_index = pd.MultiIndex.from_product([index_level1, index_level2, index_level3])\n",
    "    multi_column = pd.MultiIndex.from_product([column_level1, column_level2])\n",
    "    df_result = pd.DataFrame(index=multi_index, columns=multi_column)\n",
    "    df_result = df_result.sort_index()\n",
    "\n",
    "    index_level1 = [\"ACC\", \"PC\", \"RC\", \"F1\"]\n",
    "    index_level2 = [\"phase 1\", \"phase 2\", \"phase 3\", \"static\", \"only\"]\n",
    "    index_level3 = list(attention_types.keys()) + [\"linear\", \"slinear\", \"cubic\", \"quad\", \"gp\"]\n",
    "    column_level1 = result_order\n",
    "    column_level2 = [\"train\", \"test\"]\n",
    "    multi_index = pd.MultiIndex.from_product([index_level1, index_level2, index_level3])\n",
    "    multi_column = pd.MultiIndex.from_product([column_level1, column_level2])\n",
    "    df_pred = pd.DataFrame(index=multi_index, columns=multi_column)\n",
    "    df_pred = df_pred.sort_index()\n",
    "    ########################################################################################\n",
    "    model_type = \"Transformer\"\n",
    "    for result_version in result_order:\n",
    "        path = f\"{backup_path}/{result_version}\"\n",
    "        train_loader, test_loader = process_waveform(waveform, mc)\n",
    "        ###################################################################################\n",
    "        with (torch.no_grad()):\n",
    "            for split, data_loader in {\"train\":train_loader, \"test\":test_loader}.items():\n",
    "                print(waveform,result_version,split)\n",
    "                for batch in data_loader:\n",
    "                    x_input, x_initial, x_mask, x_output, mask, condition, interpolate = batch\n",
    "                    x_input, x_initial, x_mask, x_output, mask, condition  = x_input.to(mc.device), x_initial.to(mc.device), x_mask.to(mc.device), x_output.to(mc.device), mask.to(mc.device), condition\n",
    "                    batch_size = x_output.size(0)\n",
    "                    s_in, s_out = condition[0], condition[1]\n",
    "\n",
    "                    real = x_output.cpu().numpy()\n",
    "                    linear = x_initial.cpu().numpy()\n",
    "                    rmse_model, pcc_model, mag_model, phase_model = compute_metrics(real, linear)\n",
    "                    df_result.loc[(\"RMSE\", \"static\", \"linear\"), (result_version, split)] = rmse_model\n",
    "                    df_result.loc[(\"PCC\", \"static\", \"linear\"), (result_version, split)] = pcc_model\n",
    "\n",
    "                    rmse_model, pcc_model, mag_model, phase_model = compute_metrics(real, interpolate[1].cpu().numpy())\n",
    "                    df_result.loc[(\"RMSE\", \"static\", \"cubic\"), (result_version, split)] = rmse_model\n",
    "                    df_result.loc[(\"PCC\", \"static\", \"cubic\"), (result_version, split)] = pcc_model\n",
    "\n",
    "                    rmse_model, pcc_model, mag_model, phase_model = compute_metrics(real, interpolate[2].cpu().numpy())\n",
    "                    df_result.loc[(\"RMSE\", \"static\", \"quad\"), (result_version, split)] = rmse_model\n",
    "                    df_result.loc[(\"PCC\", \"static\", \"quad\"), (result_version, split)] = pcc_model\n",
    "            ###################################################################################\n",
    "                    data_prefix = 2\n",
    "                    # 读取模型\n",
    "                    model_type = \"Transformer\"\n",
    "                    for j, (key, attention) in enumerate(attention_types.items()):\n",
    "                        x_input, x_initial, x_mask, x_output, mask, condition, interpolate = batch\n",
    "                        x_input, x_initial, x_mask, x_output, mask, condition = x_input.to(mc.device), x_initial.to(mc.device), x_mask.to(mc.device), x_output.to(mc.device), mask.to(mc.device), condition\n",
    "                        batch_size = x_output.size(0)\n",
    "                        s_in, s_out = condition[0], condition[1]\n",
    "                        if key == \"self_conv\":\n",
    "                            mc.attention_type = [[\"original\"]*attention[0],[\"conv\"]*attention[1],[\"freq\"]*attention[2]]\n",
    "                        else:\n",
    "                            mc.attention_type = [\"original\"]*attention[0]+[\"conv\"]*attention[1]+[\"freq\"]*attention[2]\n",
    "                        # phase 1\n",
    "                        manager = ModelManager(None, mc)\n",
    "                        model = manager.create_model(model_type)\n",
    "                        generator_model_path = f\"{path}/1_generator/best_generator_{key}_{waveform}_self_{attention[0]}_conv_{attention[1]}_freq_{attention[2]}.pth\"\n",
    "                        model.load_state_dict(torch.load(generator_model_path))\n",
    "                        model.eval()\n",
    "                        for param in model.parameters():\n",
    "                            param.requires_grad = False\n",
    "                        output = model(x_input, x_initial, s_in, s_out, mask, x_mask)\n",
    "\n",
    "                        pred = output.cpu().detach().numpy()\n",
    "                        rmse_model, pcc_model, mag_model, phase_model = compute_metrics(real, pred)\n",
    "                        df_result.loc[(\"RMSE\", \"phase 1\", key), (result_version, split)] = rmse_model\n",
    "                        df_result.loc[(\"PCC\", \"phase 1\", key), (result_version, split)] = pcc_model\n",
    "                        ###################################################################################\n",
    "                        # phase 2\n",
    "                        x_input, x_initial, x_mask, x_output, mask, condition, interpolate = batch\n",
    "                        x_input, x_initial, x_mask, x_output, mask, condition = x_input.to(mc.device), x_initial.to(mc.device), x_mask.to(mc.device), x_output.to(mc.device), mask.to(mc.device), condition\n",
    "                        batch_size = x_output.size(0)\n",
    "                        s_in, s_out = condition[0], condition[1]\n",
    "\n",
    "                        manager = ModelManager(None, mc)\n",
    "                        model = manager.create_model(model_type)\n",
    "                        generator_model_path = f\"{path}/2_discriminator/best_generator_{key}_{waveform}_self_{attention[0]}_conv_{attention[1]}_freq_{attention[2]}.pth\"\n",
    "                        model.load_state_dict(torch.load(generator_model_path))\n",
    "                        model.eval()\n",
    "                        for param in model.parameters():\n",
    "                            param.requires_grad = False\n",
    "\n",
    "                        output = model(x_input, x_initial, s_in, s_out, mask, x_mask)\n",
    "                        pred = output.cpu().detach().numpy()\n",
    "                        rmse_model, pcc_model, mag_model, phase_model = compute_metrics(real, pred)\n",
    "                        df_result.loc[(\"RMSE\", \"phase 2\", key), (result_version, split)] = rmse_model\n",
    "                        df_result.loc[(\"PCC\", \"phase 2\", key), (result_version, split)] = pcc_model\n",
    "\n",
    "                        # 判别器\n",
    "                        discriminator = Discriminator(num_layers=mc.num_layers, dim_input=mc.dim_input, dim_attention=mc.dim_attention,\n",
    "                                          num_heads=mc.num_heads, dim_feedforward=mc.dim_feedforward, dropout=mc.dropout, attention_type=mc.attention_type,\n",
    "                                          with_bias=mc.with_bias).to(mc.device)\n",
    "                        discriminator_model_path = f\"{path}/2_discriminator/best_discriminator_{key}_{waveform}_self_{attention[0]}_conv_{attention[1]}_freq_{attention[2]}.pth\"\n",
    "                        discriminator.load_state_dict(torch.load(discriminator_model_path))\n",
    "                        discriminator.eval()\n",
    "                        for param in discriminator.parameters():\n",
    "                            param.requires_grad = False\n",
    "\n",
    "                        preds_on_fake = discriminator(output, s_out)\n",
    "                        preds_on_real = discriminator(x_input, s_in)\n",
    "                        preds_on_fake_bin = (torch.sigmoid(preds_on_fake).cpu() > 0.5).int().view(-1)\n",
    "                        preds_on_real_bin = (torch.sigmoid(preds_on_real).cpu() > 0.5).int().view(-1)\n",
    "                        all_preds = preds_on_real_bin.tolist() + preds_on_fake_bin.tolist()\n",
    "                        all_labels = [1] * len(preds_on_real_bin) + [0] * len(preds_on_fake_bin)\n",
    "                        acc = accuracy_score(all_labels, all_preds)\n",
    "                        precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "                        recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "                        f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "                        df_pred.loc[(\"ACC\", \"phase 2\", key), (result_version, split)] = acc\n",
    "                        df_pred.loc[(\"PC\", \"phase 2\", key), (result_version, split)] = precision\n",
    "                        df_pred.loc[(\"RC\", \"phase 2\", key), (result_version, split)] = recall\n",
    "                        df_pred.loc[(\"F1\", \"phase 2\", key), (result_version, split)] = f1\n",
    "                        ###################################################################################\n",
    "                        # phase 3\n",
    "                        x_input, x_initial, x_mask, x_output, mask, condition, interpolate = batch\n",
    "                        x_input, x_initial, x_mask, x_output, mask, condition = x_input.to(mc.device), x_initial.to(mc.device), x_mask.to(mc.device), x_output.to(mc.device), mask.to(mc.device), condition\n",
    "                        batch_size = x_output.size(0)\n",
    "                        s_in, s_out = condition[0], condition[1]\n",
    "\n",
    "                        manager = ModelManager(None, mc)\n",
    "                        model = manager.create_model(model_type)\n",
    "                        generator_model_path = f\"{path}/3_generator/best_generator_{key}_{waveform}_self_{attention[0]}_conv_{attention[1]}_freq_{attention[2]}.pth\"\n",
    "                        model.load_state_dict(torch.load(generator_model_path))\n",
    "                        model.eval()\n",
    "                        for param in model.parameters():\n",
    "                            param.requires_grad = False\n",
    "\n",
    "                        output = model(x_input, x_initial, s_in, s_out, mask, x_mask)\n",
    "                        pred = output.cpu().detach().numpy()\n",
    "                        rmse_model, pcc_model, mag_model, phase_model= compute_metrics(real, pred)\n",
    "                        df_result.loc[(\"RMSE\", \"phase 3\", key), (result_version, split)] = rmse_model\n",
    "                        df_result.loc[(\"PCC\", \"phase 3\", key), (result_version, split)] = pcc_model\n",
    "                        ###################################################################################\n",
    "                        # 判别器\n",
    "                        x_input, x_initial, x_mask, x_output, mask, condition, interpolate = batch\n",
    "                        x_input, x_initial, x_mask, x_output, mask, condition = x_input.to(mc.device), x_initial.to(mc.device), x_mask.to(mc.device), x_output.to(mc.device), mask.to(mc.device), condition\n",
    "                        batch_size = x_output.size(0)\n",
    "                        s_in, s_out = condition[0], condition[1]\n",
    "                        discriminator = Discriminator(num_layers=mc.num_layers, dim_input=mc.dim_input, dim_attention=mc.dim_attention,\n",
    "                                          num_heads=mc.num_heads, dim_feedforward=mc.dim_feedforward, dropout=mc.dropout, attention_type=mc.attention_type,\n",
    "                                          with_bias=mc.with_bias).to(mc.device)\n",
    "                        discriminator_model_path = f\"{path}/2_discriminator/best_discriminator_{key}_{waveform}_self_{attention[0]}_conv_{attention[1]}_freq_{attention[2]}.pth\"\n",
    "                        discriminator.load_state_dict(torch.load(discriminator_model_path))\n",
    "                        discriminator.eval()\n",
    "                        for param in discriminator.parameters():\n",
    "                            param.requires_grad = False\n",
    "\n",
    "                        preds_on_fake = discriminator(output, s_out)\n",
    "                        preds_on_real = discriminator(x_input, s_in)\n",
    "                        preds_on_fake_bin = (torch.sigmoid(preds_on_fake).cpu() > 0.5).int().view(-1)\n",
    "                        preds_on_real_bin = (torch.sigmoid(preds_on_real).cpu() > 0.5).int().view(-1)\n",
    "                        all_preds = preds_on_real_bin.tolist() + preds_on_fake_bin.tolist()\n",
    "                        all_labels = [1] * len(preds_on_real_bin) + [0] * len(preds_on_fake_bin)\n",
    "                        acc = accuracy_score(all_labels, all_preds)\n",
    "                        precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "                        recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "                        f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "                        df_pred.loc[(\"ACC\", \"phase 3\", key), (result_version, split)] = acc\n",
    "                        df_pred.loc[(\"PC\", \"phase 3\", key), (result_version, split)] = precision\n",
    "                        df_pred.loc[(\"RC\", \"phase 3\", key), (result_version, split)] = recall\n",
    "                        df_pred.loc[(\"F1\", \"phase 3\", key), (result_version, split)] = f1\n",
    "                        ###################################################################################\n",
    "\n",
    "\n",
    "    df_result.dropna(inplace=True)\n",
    "    df_result.to_csv(f\"{backup_path}/features_{waveform}.csv\")\n",
    "    df_features.append(df_result)\n",
    "    df_pred.dropna(inplace=True)\n",
    "    df_pred.to_csv(f\"{backup_path}/pred_{waveform}.csv\")"
   ],
   "id": "13a087f4c5731b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n",
      "electric Seed_101 train\n",
      "electric Seed_101 test\n",
      "363\n",
      "pv Seed_101 train\n",
      "pv Seed_101 test\n",
      "81\n",
      "wind Seed_101 train\n",
      "wind Seed_101 test\n",
      "364\n",
      "mpv Seed_101 train\n",
      "mpv Seed_101 test\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ac2564bbf406c63e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
